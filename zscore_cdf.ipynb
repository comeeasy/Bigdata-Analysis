{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7cd5fa",
   "metadata": {},
   "source": [
    "# 문제: zscore, cdf 계산\n",
    "성적 데이터는 n이 작지만, 정규 분포를 이룬다고 가정하자.\n",
    "\n",
    "- 1. 성적 데이터로 DataFrame을 생성\n",
    "\n",
    "- 2. zscore 컬럼을 생성. zscore를 계산하려면, 평균과 표준편차를 알아야한다. 계산식에 F 함수를 직접 사용하면 오류가 발생한다. 따로 평균과 표준편차를 구해서 계산식에서 사용해야한다.\n",
    "\n",
    "- 3. cdf 컬럼을 생성. scipy.stats.norm.cdf() 함수는 데이터 타입을 float으로 맞춰주어야한다. cdf는 평균=0, 표준편차=1을 기본 값으로 누적확률을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb22041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/01 10:38:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/01 10:38:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"zscore_cdf\")\\\n",
    "    .config(conf=pyspark.SparkConf())\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede9d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "marks=[\n",
    "    \"김하나, English, 100\",\n",
    "    \"김하나, Math, 80\",\n",
    "    \"임하나, English, 70\",\n",
    "    \"임하나, Math, 100\",\n",
    "    \"김갑돌, English, 82.3\",\n",
    "    \"김갑돌, Math, 98.5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77edd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+-----+\n",
      "|   name| subject|mark|markF|\n",
      "+-------+--------+----+-----+\n",
      "|김하나,|English,| 100|100.0|\n",
      "|김하나,|   Math,|  80| 80.0|\n",
      "|임하나,|English,|  70| 70.0|\n",
      "|임하나,|   Math,| 100|100.0|\n",
      "|김갑돌,|English,|82.3| 82.3|\n",
      "|김갑돌,|   Math,|98.5| 98.5|\n",
      "+-------+--------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "_marksRdd = spark.sparkContext.parallelize(marks).map(lambda x: x.split())\n",
    "_marksDf = spark.createDataFrame(_marksRdd, schema=[\"name\", \"subject\", \"mark\"])\n",
    "_marksDf = _marksDf.withColumn(\"markF\", _marksDf[\"mark\"].cast(FloatType()))\n",
    "_marksDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3472962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- mark: string (nullable = true)\n",
      " |-- markF: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_marksDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de63cb0",
   "metadata": {},
   "source": [
    "### zscore 계산 \n",
    "\n",
    "F 함수를 udf 함수 내에서 사용할 수 없다. 따라서 mean, std 를 미리 구해놓고 이 값을 활용해야한다.\n",
    "\n",
    "이는 아래와 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f12d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "_markStat = _marksDf.select(\n",
    "    F.mean(\"markF\").alias(\"mean\"),\n",
    "    F.stddev(\"markF\").alias(\"std\")\n",
    ").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dedd80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.46666717529297"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_markStat[0][\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9736a7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+-----+-----------+\n",
      "|   name| subject|mark|markF|     zscore|\n",
      "+-------+--------+----+-----+-----------+\n",
      "|김하나,|English,| 100|100.0|  0.9020148|\n",
      "|김하나,|   Math,|  80| 80.0| -0.6621728|\n",
      "|임하나,|English,|  70| 70.0| -1.4442666|\n",
      "|임하나,|   Math,| 100|100.0|  0.9020148|\n",
      "|김갑돌,|English,|82.3| 82.3|-0.48229098|\n",
      "|김갑돌,|   Math,|98.5| 98.5| 0.78470075|\n",
      "+-------+--------+----+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcZscore = F.udf(lambda x: (x - _markStat[0]['mean']) / _markStat[0]['std'], FloatType())\n",
    "\n",
    "_marksDf = _marksDf.withColumn(\"zscore\", calcZscore(F.col(\"markF\")))\n",
    "_marksDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a777f0",
   "metadata": {},
   "source": [
    "### cdf 계산\n",
    "\n",
    "- norm.cdf()는 numpy.float64를 반환하는데, 이는 spark에서 사용하지 않는 데이터타입이다.\n",
    "\n",
    "- float()으로 형변환을 하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b87245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "type(norm.cdf(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7da0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normCdf = F.udf(lambda x: float(norm.cdf(x)), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f5662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_marksDf = _marksDf.withColumn(\"cdf\", normCdf(F.col(\"zscore\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa2da0",
   "metadata": {},
   "source": [
    "### Window 함수를 사용하여 zscore 계산\n",
    "- 전체에 대한 평균 점수를 컬럼으로 만드려면 Window 기능을 사용해야한다.\n",
    "\n",
    "#### 전체 window\n",
    "- 점수 평균이라고 하면, spark는 어떤 평균인지 모른다. 사람별 점수 평균인지, 과목별 평균인지 알려주어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecec8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "byAll = Window.rowsBetween(-sys.maxsize, sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3971e7",
   "metadata": {},
   "source": [
    "**전체의 평균, 표준편차 컬럼을 만들고 계산**\n",
    "- 전체 Window에 대해 평균, 표준편차와 과목별 평균을 계산해보자.\n",
    "\n",
    "- 이 때, 평균, 표준편차를 컬럼으로 만든 후에 zscore를 계산해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e1f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/01 11:17:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/01 11:17:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+\n",
      "|   name| subject|mark|markF|     zscore|       cdf|             mean|            stddev|\n",
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+\n",
      "|김하나,|English,| 100|100.0|  0.9020148| 0.8164755|88.46666717529297|12.786190172956093|\n",
      "|김하나,|   Math,|  80| 80.0| -0.6621728|0.25393024|88.46666717529297|12.786190172956093|\n",
      "|임하나,|English,|  70| 70.0| -1.4442666|  0.074332|88.46666717529297|12.786190172956093|\n",
      "|임하나,|   Math,| 100|100.0|  0.9020148| 0.8164755|88.46666717529297|12.786190172956093|\n",
      "|김갑돌,|English,|82.3| 82.3|-0.48229098|0.31479964|88.46666717529297|12.786190172956093|\n",
      "|김갑돌,|   Math,|98.5| 98.5| 0.78470075|0.78368545|88.46666717529297|12.786190172956093|\n",
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "_marksDf = _marksDf.withColumn(\"mean\", F.avg(F.col(\"markF\")).over(byAll))\n",
    "_marksDf = _marksDf.withColumn(\"stddev\", F.stddev(F.col(\"markF\")).over(byAll))\n",
    "_marksDf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dfb088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bySubject = Window.partitionBy(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77c2e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/01 11:20:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/01 11:20:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+-----------------+\n",
      "|   name| subject|mark|markF|     zscore|       cdf|             mean|            stddev|    meanBySubject|\n",
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+-----------------+\n",
      "|김하나,|English,| 100|100.0|  0.9020148| 0.8164755|88.46666717529297|12.786190172956093|84.10000101725261|\n",
      "|임하나,|English,|  70| 70.0| -1.4442666|  0.074332|88.46666717529297|12.786190172956093|84.10000101725261|\n",
      "|김갑돌,|English,|82.3| 82.3|-0.48229098|0.31479964|88.46666717529297|12.786190172956093|84.10000101725261|\n",
      "|김하나,|   Math,|  80| 80.0| -0.6621728|0.25393024|88.46666717529297|12.786190172956093|92.83333333333333|\n",
      "|임하나,|   Math,| 100|100.0|  0.9020148| 0.8164755|88.46666717529297|12.786190172956093|92.83333333333333|\n",
      "|김갑돌,|   Math,|98.5| 98.5| 0.78470075|0.78368545|88.46666717529297|12.786190172956093|92.83333333333333|\n",
      "+-------+--------+----+-----+-----------+----------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_marksDf = _marksDf.withColumn(\"meanBySubject\", F.avg(F.col(\"markF\")).over(bySubject))\n",
    "_marksDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d959ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/01 11:22:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/01 11:22:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|     zscore|            zscore1|\n",
      "+-----------+-------------------+\n",
      "|  0.9020148|  0.902014804151829|\n",
      "| -0.6621728| -0.662172786480269|\n",
      "| -1.4442666| -1.444266581796318|\n",
      "|  0.9020148|  0.902014804151829|\n",
      "|-0.48229098|-0.4822909748814927|\n",
      "| 0.78470075| 0.7847007348544217|\n",
      "+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_marksDf = _marksDf.withColumn(\"zscore1\", (F.col(\"markF\") - F.col(\"mean\")) / F.col(\"stddev\"))\n",
    "_marksDf.select(\"zscore\", \"zscore1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5704789",
   "metadata": {},
   "source": [
    "**전체의 평균, 표준편차 컬럼을 만들디 않고 계산**\n",
    "- 또는 Window 함수를 직접 사용하여 zscore를 계산할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7966fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_marksDf = _marksDf\\\n",
    "    .withColumn(\"zscore2\", (F.col(\"markF\") - F.avg(\"markF\").over(byAll)) / F.stddev(\"markF\").over(byAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e967ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/01 11:26:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/01 11:26:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/01 11:26:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-------------------+\n",
      "|     zscore|            zscore1|            zscore2|\n",
      "+-----------+-------------------+-------------------+\n",
      "|  0.9020148|  0.902014804151829|  0.902014804151829|\n",
      "| -0.6621728| -0.662172786480269| -0.662172786480269|\n",
      "| -1.4442666| -1.444266581796318| -1.444266581796318|\n",
      "|  0.9020148|  0.902014804151829|  0.902014804151829|\n",
      "|-0.48229098|-0.4822909748814927|-0.4822909748814927|\n",
      "| 0.78470075| 0.7847007348544217| 0.7847007348544217|\n",
      "+-----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_marksDf.select(\"zscore\", \"zscore1\", \"zscore2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7287d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_analysis",
   "language": "python",
   "name": "bigdata_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
